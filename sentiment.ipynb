{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import tqdm\n",
    "# from deeppavlov import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 22:48:16.592 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/classifiers/rusentiment_convers_bert/rusentiment_convers_bert_torch.tar.gz download because of matching hashes\n",
      "c:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = build_model('rusentiment_convers_bert', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sentiment = pd.read_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>numwords</th>\n",
       "      <th>userid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Мало кто может спеть «Кукушку» Цоя так же хоро...</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>101049741</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Автобус в Таллин: контактная информация</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>10360086</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В Петербурге живут самые читающие коты</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>10360086</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Иринка родная, С Днем Рождения!!!))) Здорлвья ...</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>10360340</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Коля, с Рождеством Христовым!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>103606625</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  gender  age  numwords  \\\n",
       "0  Мало кто может спеть «Кукушку» Цоя так же хоро...       1   61        17   \n",
       "1            Автобус в Таллин: контактная информация       1   61         5   \n",
       "2             В Петербурге живут самые читающие коты       1   61         6   \n",
       "3  Иринка родная, С Днем Рождения!!!))) Здорлвья ...       1   61        10   \n",
       "4                    Коля, с Рождеством Христовым!!!       1   61         4   \n",
       "\n",
       "      userid  year  \n",
       "0  101049741  2015  \n",
       "1   10360086  2014  \n",
       "2   10360086  2015  \n",
       "3   10360340  2021  \n",
       "4  103606625  2021  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_path = f'datasets/{age}_{gender}_0_150.csv'\n",
    "# try:\n",
    "#     df = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "# except:\n",
    "#     dataset_path = f'datasets/{age}_{gender}_0_150'\n",
    "#     df = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "# df.replace('þ<br />þ', '\\n ', regex=True, inplace=True)\n",
    "# df.head()\n",
    "# data = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 500\n",
    "# batched_sentiment = []\n",
    "# for i in range(0, len(data), batch_size):\n",
    "#   batched_sentiment.append(model(data[i : i+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = 0\n",
    "minus = 0\n",
    "neutral = 0\n",
    "speech = 0\n",
    "for batch in batched_sentiment:\n",
    "  for sent in batch:\n",
    "    if sent == 'positive':\n",
    "      plus += 1\n",
    "    elif sent == 'negative':\n",
    "      minus += 1\n",
    "    elif sent == 'neutral':\n",
    "      neutral += 1\n",
    "    elif sent == 'speech':\n",
    "      speech += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>265630</td>\n",
       "      <td>137348</td>\n",
       "      <td>391052</td>\n",
       "      <td>89173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>162755</td>\n",
       "      <td>129985</td>\n",
       "      <td>532093</td>\n",
       "      <td>56005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>272967</td>\n",
       "      <td>138353</td>\n",
       "      <td>378102</td>\n",
       "      <td>98666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>175376</td>\n",
       "      <td>138872</td>\n",
       "      <td>495780</td>\n",
       "      <td>66262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>278213</td>\n",
       "      <td>133324</td>\n",
       "      <td>383801</td>\n",
       "      <td>101186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>181456</td>\n",
       "      <td>140761</td>\n",
       "      <td>485964</td>\n",
       "      <td>70251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>283494</td>\n",
       "      <td>123207</td>\n",
       "      <td>397761</td>\n",
       "      <td>102808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>180638</td>\n",
       "      <td>137142</td>\n",
       "      <td>494811</td>\n",
       "      <td>73081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>287515</td>\n",
       "      <td>110922</td>\n",
       "      <td>417101</td>\n",
       "      <td>102661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>180244</td>\n",
       "      <td>130807</td>\n",
       "      <td>505819</td>\n",
       "      <td>75518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>290698</td>\n",
       "      <td>98964</td>\n",
       "      <td>434275</td>\n",
       "      <td>102130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>180347</td>\n",
       "      <td>124178</td>\n",
       "      <td>520410</td>\n",
       "      <td>76377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>221493</td>\n",
       "      <td>49128</td>\n",
       "      <td>616331</td>\n",
       "      <td>75220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>123617</td>\n",
       "      <td>89534</td>\n",
       "      <td>699841</td>\n",
       "      <td>43098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>216856</td>\n",
       "      <td>49758</td>\n",
       "      <td>619714</td>\n",
       "      <td>75988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>120827</td>\n",
       "      <td>88532</td>\n",
       "      <td>701239</td>\n",
       "      <td>43348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>212055</td>\n",
       "      <td>50422</td>\n",
       "      <td>624626</td>\n",
       "      <td>76718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>119483</td>\n",
       "      <td>87293</td>\n",
       "      <td>705498</td>\n",
       "      <td>43654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>210894</td>\n",
       "      <td>51602</td>\n",
       "      <td>620960</td>\n",
       "      <td>78205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>114957</td>\n",
       "      <td>88885</td>\n",
       "      <td>709974</td>\n",
       "      <td>43128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>193094</td>\n",
       "      <td>49744</td>\n",
       "      <td>595095</td>\n",
       "      <td>73930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>110681</td>\n",
       "      <td>89435</td>\n",
       "      <td>715902</td>\n",
       "      <td>42010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>175571</td>\n",
       "      <td>49958</td>\n",
       "      <td>557299</td>\n",
       "      <td>70098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>104094</td>\n",
       "      <td>98398</td>\n",
       "      <td>711989</td>\n",
       "      <td>40704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>76182</td>\n",
       "      <td>29725</td>\n",
       "      <td>334770</td>\n",
       "      <td>47387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33298</td>\n",
       "      <td>38539</td>\n",
       "      <td>293586</td>\n",
       "      <td>17648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>71747</td>\n",
       "      <td>29358</td>\n",
       "      <td>300688</td>\n",
       "      <td>45323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32314</td>\n",
       "      <td>35652</td>\n",
       "      <td>280497</td>\n",
       "      <td>17411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>66592</td>\n",
       "      <td>25721</td>\n",
       "      <td>272697</td>\n",
       "      <td>42225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>29348</td>\n",
       "      <td>36187</td>\n",
       "      <td>266910</td>\n",
       "      <td>15249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>56460</td>\n",
       "      <td>23419</td>\n",
       "      <td>243640</td>\n",
       "      <td>36624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>26358</td>\n",
       "      <td>33360</td>\n",
       "      <td>233851</td>\n",
       "      <td>13977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>50142</td>\n",
       "      <td>22596</td>\n",
       "      <td>218170</td>\n",
       "      <td>33182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>22612</td>\n",
       "      <td>30959</td>\n",
       "      <td>213866</td>\n",
       "      <td>12004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>46294</td>\n",
       "      <td>21290</td>\n",
       "      <td>189987</td>\n",
       "      <td>30357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>20684</td>\n",
       "      <td>30267</td>\n",
       "      <td>198686</td>\n",
       "      <td>11473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  positive  negative  neutral  speech\n",
       "0    16       1    265630    137348   391052   89173\n",
       "1    16       2    162755    129985   532093   56005\n",
       "2    17       1    272967    138353   378102   98666\n",
       "3    17       2    175376    138872   495780   66262\n",
       "4    18       1    278213    133324   383801  101186\n",
       "5    18       2    181456    140761   485964   70251\n",
       "6    19       1    283494    123207   397761  102808\n",
       "7    19       2    180638    137142   494811   73081\n",
       "8    20       1    287515    110922   417101  102661\n",
       "9    20       2    180244    130807   505819   75518\n",
       "10   21       1    290698     98964   434275  102130\n",
       "11   21       2    180347    124178   520410   76377\n",
       "12   38       1    221493     49128   616331   75220\n",
       "13   38       2    123617     89534   699841   43098\n",
       "14   39       1    216856     49758   619714   75988\n",
       "15   39       2    120827     88532   701239   43348\n",
       "16   40       1    212055     50422   624626   76718\n",
       "17   40       2    119483     87293   705498   43654\n",
       "18   41       1    210894     51602   620960   78205\n",
       "19   41       2    114957     88885   709974   43128\n",
       "20   42       1    193094     49744   595095   73930\n",
       "21   42       2    110681     89435   715902   42010\n",
       "22   43       1    175571     49958   557299   70098\n",
       "23   43       2    104094     98398   711989   40704\n",
       "24   58       1     76182     29725   334770   47387\n",
       "25   58       2     33298     38539   293586   17648\n",
       "26   59       1     71747     29358   300688   45323\n",
       "27   59       2     32314     35652   280497   17411\n",
       "28   60       1     66592     25721   272697   42225\n",
       "29   60       2     29348     36187   266910   15249\n",
       "30   61       1     56460     23419   243640   36624\n",
       "31   61       2     26358     33360   233851   13977\n",
       "32   62       1     50142     22596   218170   33182\n",
       "33   62       2     22612     30959   213866   12004\n",
       "34   63       1     46294     21290   189987   30357\n",
       "35   63       2     20684     30267   198686   11473"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentiment = pd.read_csv('sentiment.csv')\n",
    "data_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>56460</td>\n",
       "      <td>23419</td>\n",
       "      <td>243640</td>\n",
       "      <td>36624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  positive  negative  neutral  speech\n",
       "0   61       1     56460     23419   243640   36624"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame({'age': [age], 'gender': [gender], 'positive': [plus], 'negative': [minus], 'neutral': [neutral], 'speech': [speech]})\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>46294</td>\n",
       "      <td>21290</td>\n",
       "      <td>189987</td>\n",
       "      <td>30357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>50142</td>\n",
       "      <td>22596</td>\n",
       "      <td>218170</td>\n",
       "      <td>33182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>56460</td>\n",
       "      <td>23419</td>\n",
       "      <td>243640</td>\n",
       "      <td>36624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  positive  negative  neutral  speech\n",
       "0   63       1     46294     21290   189987   30357\n",
       "1   62       1     50142     22596   218170   33182\n",
       "0   61       1     56460     23419   243640   36624"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentiment = pd.concat((data_sentiment, df_temp))\n",
    "data_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentiment.to_csv('sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "age = 61\n",
    "gender = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sismetanin/rubert-ru-sentiment-rusentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"sismetanin/rubert-ru-sentiment-rusentiment\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'datasets/{age}_{gender}_0_150.csv'\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "except:\n",
    "    dataset_path = f'datasets/{age}_{gender}_0_150'\n",
    "    df = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "df.replace('þ<br />þ', '\\n ', regex=True, inplace=True)\n",
    "df.head()\n",
    "data = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 9599, 102]], 'token_type_ids': [[0, 0, 0]], 'attention_mask': [[1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['дома'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_batch_apply(data):\n",
    "    with torch.no_grad():\n",
    "        tok_out = tokenizer(data, padding=True)\n",
    "        print(max([len(i) for i in data]))\n",
    "        tok_out_cuda = dict((k, torch.tensor(v).to(device)) for k, v in tok_out.items())\n",
    "        print(tok_out_cuda)\n",
    "        print(list(v.size() for k, v in tok_out_cuda.items()))\n",
    "        out = model(**tok_out_cuda)\n",
    "        ans = torch.argmax(torch.sigmoid(out['logits']), axis=1).cpu().numpy()\n",
    "        # tok_out_cuda = dict((k, torch.tensor(v).to('cpu')) for k, v in tok_out.items())\n",
    "    return ans\n",
    "\n",
    "def model_one_apply(data: str):\n",
    "    with torch.no_grad():\n",
    "        tok_out = tokenizer([data])\n",
    "        tok_out_cuda = dict((k, torch.tensor(v).to(device)) for k, v in tok_out.items())\n",
    "        out = model(**tok_out_cuda)\n",
    "        ans = torch.argmax(torch.sigmoid(out['logits']), axis=1).cpu().numpy()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "{'input_ids': tensor([[  101, 15662, 10962,  ...,     0,     0,     0],\n",
      "        [  101, 14851,   845,  ...,     0,     0,     0],\n",
      "        [  101,   845, 22972,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   845, 15934,  ...,     0,     0,     0],\n",
      "        [  101,  7084, 83774,  ...,     0,     0,     0],\n",
      "        [  101, 75345,  2630,  ...,     0,     0,     0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 187]), torch.Size([50, 187]), torch.Size([50, 187])]\n",
      "[2, 1, 1, 4, 4, 4, 1, 1, 1, 1, 2, 2, 1, 2, 4, 2, 1, 4, 1, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 4, 2, 1, 1, 1, 3, 1, 1, 3, 1, 4, 1, 3, 1, 1, 3, 3, 1, 1, 1]\n",
      "229\n",
      "{'input_ids': tensor([[  101, 63446, 13656,  ...,     0,     0,     0],\n",
      "        [  101, 17051, 13381,  ...,     0,     0,     0],\n",
      "        [  101,  3240,   880,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   625,  1516,  ...,     0,     0,     0],\n",
      "        [  101, 11144,  1568,  ...,   102,     0,     0],\n",
      "        [  101,  6818,   875,  ...,     0,     0,     0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 56]), torch.Size([50, 56]), torch.Size([50, 56])]\n",
      "[1, 1, 1, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 4, 1, 1, 4, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 3, 3, 3]\n",
      "211\n",
      "{'input_ids': tensor([[   101, 118314,   7435,  ...,      0,      0,      0],\n",
      "        [   101,  60618,   8235,  ...,      0,      0,      0],\n",
      "        [   101,  78315,  41052,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [   101,  75118,    130,  ...,      0,      0,      0],\n",
      "        [   101,   9629,  59238,  ...,      0,      0,      0],\n",
      "        [   101,  20164,  42753,  ...,      0,      0,      0]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 59]), torch.Size([50, 59]), torch.Size([50, 59])]\n",
      "[3, 1, 2, 2, 1, 2, 2, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 2, 3, 1, 1, 1, 3, 2, 2, 1, 1, 1, 3, 3, 4, 4, 4, 4, 4, 4, 4, 1, 2, 1, 1]\n",
      "652\n",
      "{'input_ids': tensor([[   101,    146,  19896,  ...,      0,      0,      0],\n",
      "        [   101, 110837,  24748,  ...,      0,      0,      0],\n",
      "        [   101,  33193,   6399,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [   101,    290,    290,  ...,      0,      0,      0],\n",
      "        [   101,    290,    290,  ...,      0,      0,      0],\n",
      "        [   101,    290,    290,  ...,      0,      0,      0]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 180]), torch.Size([50, 180]), torch.Size([50, 180])]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 1, 3, 4, 2, 1, 0, 1, 1, 1, 1, 4, 4, 1, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1]\n",
      "937\n",
      "{'input_ids': tensor([[   101, 106061,   8350,  ...,      0,      0,      0],\n",
      "        [   101,    290,    290,  ...,      0,      0,      0],\n",
      "        [   101,    100,   3487,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [   101,  30201,  50308,  ...,      0,      0,      0],\n",
      "        [   101,  40648,  11087,  ...,      0,      0,      0],\n",
      "        [   101,   2785,  17418,  ...,      0,      0,      0]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 216]), torch.Size([50, 216]), torch.Size([50, 216])]\n",
      "[4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 4, 4, 4, 2, 2, 3, 4, 1, 4, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "706\n",
      "{'input_ids': tensor([[  101, 21230,  3629,  ...,     0,     0,     0],\n",
      "        [  101,  7805, 13193,  ...,     0,     0,     0],\n",
      "        [  101,  2306,  8824,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 62962, 40648,  ...,     0,     0,     0],\n",
      "        [  101, 32608,  3648,  ...,     0,     0,     0],\n",
      "        [  101,  2739,  1469,  ...,     0,     0,     0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 180]), torch.Size([50, 180]), torch.Size([50, 180])]\n",
      "[1, 2, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 4, 1, 4, 1, 1, 2, 4, 4, 1, 0, 4, 4, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 4, 4, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 4, 1, 1]\n",
      "1345\n",
      "{'input_ids': tensor([[   101, 118933,    848,  ...,      0,      0,      0],\n",
      "        [   101,    875,  26269,  ...,      0,      0,      0],\n",
      "        [   101,    845,  31289,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [   101,    140,    888,  ...,      0,      0,      0],\n",
      "        [   101,   5190,  43578,  ...,      0,      0,      0],\n",
      "        [   101,  26648,   5315,  ...,      0,      0,      0]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "[torch.Size([50, 575]), torch.Size([50, 575]), torch.Size([50, 575])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (575) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m batched_sentiment \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(data), batch_size):\n\u001b[1;32m----> 4\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(model_batch_apply(data[i: i \u001b[39m+\u001b[39;49m batch_size])))\n",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m, in \u001b[0;36mmodel_batch_apply\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(tok_out_cuda)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(v\u001b[39m.\u001b[39msize() \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tok_out_cuda\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m----> 8\u001b[0m out \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtok_out_cuda)\n\u001b[0;32m      9\u001b[0m ans \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(torch\u001b[39m.\u001b[39msigmoid(out[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     10\u001b[0m \u001b[39m# tok_out_cuda = dict((k, torch.tensor(v).to('cpu')) for k, v in tok_out.items())\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1556\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1548\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1556\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1557\u001b[0m     input_ids,\n\u001b[0;32m   1558\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1559\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1560\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1561\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1562\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1563\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1564\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1565\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1566\u001b[0m )\n\u001b[0;32m   1568\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1570\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1011\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1011\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1012\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1013\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1014\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1015\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1016\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1017\u001b[0m )\n\u001b[0;32m   1018\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1019\u001b[0m     embedding_output,\n\u001b[0;32m   1020\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1029\u001b[0m )\n\u001b[0;32m   1030\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Димас\\venvs\\main_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:241\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    240\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 241\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m    242\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    243\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (575) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "batched_sentiment = []\n",
    "for i in range(0, len(data), batch_size):\n",
    "  print(list(model_batch_apply(data[i: i + batch_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.sigmoid(out['logits']), axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pred = {\n",
    "    0 : 'negative',\n",
    "    1 : 'neutral',\n",
    "    2 : 'positive',\n",
    "    3 : 'skip',\n",
    "    4 : 'speech'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_pred[torch.argmax(torch.sigmoid(out['logits'])).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_pred[model_one_apply('пьянчуга')[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
